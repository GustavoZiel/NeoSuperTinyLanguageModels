generator:
  seed: 42
  
  # Generation parameters
  temperature: 0.3
  top_k: 10
  max_new_tokens: 10
  steps_to_log: 3
  
  # Whether to
  generate: true
  eval_rank: true
  eval_perplexity: true

  # Either provide a path to a file containing prompts, inline list of prompts, or let it be empty for interactive mode.
  input_prompts:
    - sentence: "Albert Einstein was born on" 
      answer: " March 14, 1879"
    - sentence: "Isaac Newton was born on"
      answer: " January 4, 1643"
  # input_prompts: "configs/prompts/capitals.yaml"
  # input_prompts: "configs/prompts/date_of_birth.yaml"

model_ckpts:
  # Here you can specify either Hugging Face model names or local checkpoint paths.
  # Be aware that specifying Hugging Face models will download them at runtime, which may take time and require internet access.

  # https://huggingface.co/Qwen/Qwen3-0.6B-Base 
  # - "Qwen/Qwen3-0.6B-Base"

  # https://huggingface.co/openai-community/gpt2
  - "openai-community/gpt2"

  # https://huggingface.co/EleutherAI/pythia-6.9b
  - "EleutherAI/pythia-70m"
  # - "EleutherAI/pythia-160m"
  # - "EleutherAI/pythia-410m"

  # Examples of larger models (uncomment to use)
  # - "EleutherAI/pythia-1b"
  # - "EleutherAI/pythia-1.4b"
  # - "EleutherAI/pythia-2.8b"
  # - "EleutherAI/pythia-6.9b"
  # - "EleutherAI/pythia-12b"

  # STLMs from checkpoints (saved in local dir 'checkpoints/')
  # Checkpoint files format: YYYYMMDD_HHMM_datasetname_iterorepochs.pt
  # - checkpoints/20250929_1115_simple_en_wiki_50000.pt
